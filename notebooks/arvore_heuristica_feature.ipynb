{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Árvore de decisão - Heurística para escolher o melhor valor de cada característica"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definir implementações"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funções utilitárias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Tuple, Any\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def most_frequently(y: ndarray):\n",
    "    return Counter(y.flat).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def gini_impurity(y: ndarray):\n",
    "    labels = sorted(set(y))\n",
    "    y_len = len(y)\n",
    "    probabilities = numpy.zeros(shape=(len(labels),))\n",
    "\n",
    "    for index, key in enumerate(labels):\n",
    "        probabilities[index] = sum(y == key) / y_len\n",
    "    return 1 - sum(probabilities ** 2)\n",
    "\n",
    "\n",
    "def gini_impurity_by_value(x: ndarray, y: ndarray, value):\n",
    "    same = x == value\n",
    "    impurity_eq = gini_impurity(y[same])\n",
    "    probability_eq = sum(same) / len(y)\n",
    "    impurity_diff = gini_impurity(y[~same])\n",
    "    probability_diff = sum(~same) / len(y)\n",
    "    return impurity_eq * probability_eq + impurity_diff * probability_diff\n",
    "\n",
    "\n",
    "def gini_min_impurity(x: ndarray, y: ndarray) -> Tuple[float, int, Any]:\n",
    "    impurities = []\n",
    "    features_values = []\n",
    "    features_index = list(range(x.shape[1]))\n",
    "\n",
    "    for i in features_index:\n",
    "        values = sorted(set(x[:, i]))\n",
    "\n",
    "        for value in values:\n",
    "            features_values.append([i, value])\n",
    "            impurity_value_feat = gini_impurity_by_value(x[:, i], y, value)\n",
    "            impurities.append(impurity_value_feat)\n",
    "\n",
    "    features_values = numpy.array(features_values)\n",
    "    min_impurity = numpy.argmin(impurities)\n",
    "    feature, value = features_values[min_impurity]\n",
    "    return impurities[min_impurity], int(feature), value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Heurística escolhida"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementação do professor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class Tree(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.feature = 0\n",
    "\n",
    "    def fit(self, x: ndarray, y: ndarray):\n",
    "        self.value = numpy.mean(x[:, self.feature])\n",
    "        greater = x[:, self.feature] > self.value\n",
    "\n",
    "        if sum(greater) > 0 and sum(~greater) > 0:\n",
    "            self.greater = Tree()\n",
    "            self.greater.fit(x[greater, :], y[greater])\n",
    "            self.lte = Tree()\n",
    "            self.lte.fit(x[~greater, :], y[~greater])\n",
    "\n",
    "        else:\n",
    "            self.answer = most_frequently(y)\n",
    "\n",
    "    def predict(self, x: ndarray):\n",
    "        y = numpy.empty((x.shape[0]))\n",
    "\n",
    "        if hasattr(self, 'answer'):\n",
    "            y[:] = self.answer\n",
    "\n",
    "        else:\n",
    "            greater = x[:, self.feature] > self.value\n",
    "            y[greater] = self.greater.predict(x[greater, :])\n",
    "            y[~greater] = self.lte.predict(x[~greater, :])\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementação do Scikit-Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "iris_x, iris_y = iris_dataset.data[:, 2:], iris_dataset.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparação: Regiões de decisão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: finalizar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparação"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "test_score_key = 'test_score'\n",
    "\n",
    "zero_r = DummyClassifier(strategy=\"most_frequent\")\n",
    "zero_r.fit(iris_x, iris_y)\n",
    "zero_r_predict = zero_r.predict(iris_x)\n",
    "model = DummyClassifier(strategy=\"most_frequent\")\n",
    "zero_r_cross_val = cross_validate(model, iris_x, iris_y)[test_score_key]\n",
    "\n",
    "tree = Tree()\n",
    "tree.fit(iris_x, iris_y)\n",
    "tree_predict = tree.predict(iris_x)\n",
    "model = Tree()\n",
    "tree_cross_val = cross_validate(model, iris_x, iris_y)[test_score_key]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Zero R  Árvore (prof.)\nAcurácia                   0.333333        0.953333\nValidação cruzada (média)  0.333333        0.920000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Zero R</th>\n      <th>Árvore (prof.)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Acurácia</th>\n      <td>0.333333</td>\n      <td>0.953333</td>\n    </tr>\n    <tr>\n      <th>Validação cruzada (média)</th>\n      <td>0.333333</td>\n      <td>0.920000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "iris_x = {\n",
    "    'Acurácia': [\n",
    "        accuracy_score(iris_y, zero_r_predict),\n",
    "        accuracy_score(iris_y, tree_predict)\n",
    "    ],\n",
    "    'Validação cruzada (média)': [\n",
    "        numpy.mean(zero_r_cross_val),\n",
    "        numpy.mean(tree_cross_val)\n",
    "    ]\n",
    "}\n",
    "\n",
    "columns = ['Zero R', 'Árvore (prof.)']\n",
    "DataFrame.from_dict(iris_x, orient='index', columns=columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
